#!/bin/bash

###############################################################################
# Specific procedures:
###############################################################################

#------------------------------------------------------------------------------
# Attempts to stop the container gracefully in case of receive SIGTERM signal from Docker:
#------------------------------------------------------------------------------
stop_container()
{
    echo "############################################################################################################"
    echo "SIGTERM signal received at: $(date "+%Y-%m-%d %H:%M:%S")"
    # To DO: Terminate or kill background processes before to exit.
    echo "Container Stopped."
    echo ""
    exit 0
}

#------------------------------------------------------------------------------
# Check if VMs in CHECK_PATCH_LIST are patched for incremental backups (and applies it when possible):
#------------------------------------------------------------------------------
check_patch()
{
    # Lists to add VMs (and summarize at the end):
    local domain_shutdown_success
    local domain_shutdown_failed
    local vm_patch_success
    local vm_patch_failed

    echo ""
    echo "____________________________________________________________________________________________________________"
    echo "Checking for incremental backup patch on Virtual machines: ${CHECK_PATCH_LIST[@]}"

    local i=0
    for domain in ${CHECK_PATCH_LIST[@]}; do

        # For each VM, the loop repeats itself as needed until a VM has been successfully patched, or not:
        echo ""

        while true; do

            if [[ -z ${domain_shutdown_failed[$i]} && -z ${vm_patch_failed[$i]} ]]; then

                if [[ $(domain_is_patched $domain ) == yes ]]; then

                    echo "$domain: Incremental backup patch is OK"
                    vm_patch_success[$i]+=$domain
                    break

                elif [[ $(domain_is_patched $domain --inactive) == yes ]]; then

                    # VM is (presumably) running and was patched before (e.g. in past iteration inside this loop)
                    echo "$domain: Incremental backup patch is present, but a power cycle is required to apply changes"

                    if [[ ! -z $VM_ALLOW_POWERCYCLE ]]; then

                        # When permission is granted, and past iteration over the VM haven't triggered errors, attempts shuts down the VM temporarily:
                        domain_shutdown $domain --wait $VM_WAIT_TIME

                        if [[ $? -eq 0 ]]; then

                            # Adds VM to shutdown success local list:
                            domain_shutdown_success[$i]+=$domain
                        else

                            # Adds VM to failed to shutdown local list
                            # (This VM might shutdown eventually):
                            domain_shutdown_failed[$i]=$domain
                        fi
                    else

                        # Adds VM to failed to shutdown local list
                        # (User must shutdown the VM manually):
                        domain_shutdown_failed[$i]=$domain
                    fi

                    # Restarts the loop (checks VM again under changed conditions):
                    continue

                else

                    echo "$domain: Incremental backup patch not found. Attempting to patch..."

                    vm-patch $domain --quiet

                    # IF fails, add VM to failed to patch local list:
                    [[ $? -eq 0 ]] && echo "$domain: Successfully patched!" ||  { vm_patch_failed[$i]=$domain; echo "$domain: Failed!"; }

                    # Restarts the loop (checks VM again under changed condition):
                    continue
                fi
            else

                # Failed either shutting down or applying the patch
                # Nothing else possible to do:
                break
            fi
        done

        # Increases the index to check the next VM:
        ((i++))
    done

    # Flush CHECK_PATCH_LIST:
    unset CHECK_PATCH_LIST

    # Appends sub-list of (successfully) patched VMs to global CHECK_BACKUPS_LIST:
    CHECK_BACKUPS_LIST+=(${vm_patch_success[@]})

    # Appends sub-list to the global list of powered OFF VMs:
    POWEREDOFF_VMS_LIST+=(${domain_shutdown_success[@]})

    # Appends sub list of VMs that failed to shutdown to global SHUTDOWN_REQUIRED_VMS_LIST:
    SHUTDOWN_REQUIRED_VMS_LIST+=(${domain_shutdown_failed[@]})

    # Appends sub list of failed VMs:
    FAILED_VMS_LIST+=(${vm_patch_failed[@]})

    echo ""
    echo "Incremental Backup Patch Summary:"
    echo ""
    echo "Patched for backups:          ${vm_patch_success[@]:-"None"}"
    [[ ! -z $VM_ALLOW_POWERCYCLE ]] && \
    echo "Into automatic power cycle:   ${domain_shutdown_success[@]:-"None"}" || \
    echo "Manual shut down is required: ${domain_shutdown_failed[@]:-"None"}"
    echo "Could not apply patch:        ${vm_patch_failed[@]:-"None"}"

    if [[ -z ${domain_shutdown_failed[@]} && -z ${vm_patch_failed[@]} ]]; then

        echo ""
        echo "All VMs patched successfuly!"
    fi
}

#------------------------------------------------------------------------------
# Checks VMs in CHECK_BACKUPS_LIST for backup chain integrity (and puts VMs at point of create new backup chains, if possible):
#------------------------------------------------------------------------------
check_backups()
{
    # Local variables used for flow control:
    local backup_check_failed
    local backup_chain_full
    local backup_folder_integrity
    local bitmaps_list
    local checkpoint_list
    local recoverable_backup_chain

    # Lists to add VMs (and summarize at the end):
    local broken_or_full_backup_chain
    local domain_shutdown_failed
    local domain_shutdown_success
    local preserved_backup_chain

    echo ""
    echo "____________________________________________________________________________________________________________"
    echo "Checking backup chain ingtegrity on Virtual machines: ${CHECK_BACKUPS_LIST[@]}"

    local i=0
    for domain in ${CHECK_BACKUPS_LIST[@]}; do

        backup_check_failed=""
        backup_chain_full=""
        backup_folder_integrity=""
        checkpoint_list=()
        recoverable_backup_chain=""

        echo ""

        while true; do

            # Checks once for non existing, corrupted or dummy backup folders and partial checkpoints:
            #------------------------------------------------------------------------------
            if [[ -z $backup_folder_integrity || -z $recoverable_backup_chain || -z $backup_chain_full ]]; then

                if [[ ! -d $LOCAL_BACKUP_PATH/$domain \
                    || ! -f $LOCAL_BACKUP_PATH/$domain/$domain.cpt \
                    || ! -d $LOCAL_BACKUP_PATH/$domain/checkpoints ]]; then

                    backup_folder_integrity="false"
                    echo "$domain: No backup chain folder detected, or internal structure is inconsistent"

                elif [[ ! -z $(find $LOCAL_BACKUP_PATH/$domain -type f -name "*.partial") ]]; then

                    local damaged_backup_checkpoint_list=($(backup_checkpoint_list $LOCAL_BACKUP_PATH/$domain))

                    if [[ ${#damaged_backup_checkpoint_list[@]} -eq 1 ]]; then

                        # Backup chain is useless:
                        backup_folder_integrity="false"
                        echo "$domain: A full backup operation was previously cancelled. This backup chain is unrecoverable, therefore will be removed"

                    elif [[ $RESTARTED_SERVER == true ]]; then

                        # Backup chain may be recoverable, but can't proceed since checkpoint metadata doesn't exist under this Unraid scenario:
                        recoverable_backup_chain="false"
                        echo "$domain: An incremental backup operation was previously cancelled and RESTARTED_SERVER mode is active, not leaving chances to repair it. A new backup chain will be created"

                    elif [[ -z $VM_ALLOW_POWERCYCLE ]]; then

                        # Backup chain may be recoverable, but can't proceed since it can't shut down the VM:
                        recoverable_backup_chain="false"
                        echo "$domain: An incremental backup operation was previously cancelled and environment variable VM_ALLOW_POWERCYCLE is not set (cannot attempt to repair). A new backup chain will be created"

                    else

                        # Backup chain may be recoverable, and will attempt to repair it:
                        recoverable_backup_chain="true"
                        echo "$domain: An incremental backup operation was previously cancelled. It will attempt to fix the current backup chain by deleting the (now useless) data that was being saved right before the cancellation, and deleting the checkpoint from this VM (a full Power Cycle will be performed after repair to apply all the changes)"
                    fi

                else

                    # Backup folder integrity looks OK, check for 1sr part of retention policy.
                    # Retireve the number of checkpoints in the backup chain:
                    local num_of_backup_checkpoints=$(backup_checkpoint_list $LOCAL_BACKUP_PATH/$domain --num)

                    if [[ ! -z $MAX_BACKUPS_PER_CHAIN && $num_of_backup_checkpoints -ge $MAX_BACKUPS_PER_CHAIN ]]; then

                        # Backup chain is full, a new one will be created:
                        backup_chain_full="true"

                        # Mark backup chain status as full:
                        broken_or_full_backup_chain[$i]=$domain

                        echo "$domain: Backup chain contains $num_of_backup_checkpoints checkpoints, and the limit set in environment variable MAX_BACKUPS_PER_CHAIN is $MAX_BACKUPS_PER_CHAIN. A new backup chain will be created"

                    else

                        # Everything looks good to go:
                        backup_folder_integrity="true"

                        # Display checkpoints limits, if set:
                        [[ ! -z $MAX_BACKUPS_PER_CHAIN ]] && local display_checkpoint_limit=" out of $MAX_BACKUPS_PER_CHAIN"

                        echo "$domain: Detected $num_of_backup_checkpoints$display_checkpoint_limit checkpoints"
                    fi
                fi
            fi

            # Checks once if RESTARTED_SERVER is true, VM is running and VM_ALLOW_POWERCYCLE is set
            # (Will fail if can't shut down the VM):
            #------------------------------------------------------------------------------
            if [[ $RESTARTED_SERVER == true && $(domain_state $domain) == running ]]; then

                if [[ ! -z $VM_ALLOW_POWERCYCLE ]]; then

                    # Attempts to shut down the VM temporarily:
                        domain_shutdown $domain --wait $VM_WAIT_TIME

                        if [[ $? -eq 0 ]]; then

                            # Adds VM to shutdown success local list:
                            domain_shutdown_success[$i]=$domain

                            # Restarts the loop (checks backup again under changed condition):
                            continue
                        else

                            # Adds VM to failed to shutdown local list
                            # (This VM might shutdown eventually):
                            domain_shutdown_failed[$i]=$domain

                            # Exits the loop (nothing else can be done):
                            break
                        fi
                else
                    # (User must shutdown the VM manually):
                    echo "$domain: Cannot check backup chain integrity while VM is running (RESTARTED_SERVER mode is enabled)"

                    # Adds VM to failed to shutdown local list:
                    domain_shutdown_failed[$i]=$domain

                    # Exits the loop (nothing else can be done):
                    break
                fi
            fi

            # Performs a deep check when VM is shut down:
            #------------------------------------------------------------------------------
            if [[ $(domain_state $domain) == "shut off" ]]; then


                # Backup chain is worth of being checked:
                #------------------------------------------------------------------------------
                if [[ $backup_folder_integrity == true || $recoverable_backup_chain == true ]]; then

                echo "$domain: Is shut down, performing a full check into its backup chain..."

                    if [[ $RESTARTED_SERVER == true ]] ; then

                        # No QEMU checkpoints are found in this specific state. Falls back to checkpoints in backup:

                        echo "$domain: Reading checkpoints list from backup"
                        checkpoint_list=($(backup_checkpoint_list $LOCAL_BACKUP_PATH/$domain))
                    else

                        echo "$domain: Reading checkpoints list from QEMU"
                        checkpoint_list=($(domain_checkpoint_list $domain))
                    fi

                    # Perform a full check of checkpoints vs bitmaps:
                    for image in $(domain_img_paths_list $domain); do

                        bitmaps_list=($(disk_image_bitmap_list $image))

                        if [[ ${bitmaps_list[@]} != ${checkpoint_list[@]} ]]; then

                            backup_check_failed="true"
                            echo "$domain: Checkpoints and bitmaps lists on disk $image MISMATCH"

                            # Nothing else can be done
                            break

                        elif [[ ! -z ${bitmaps_list[@]} ]]; then

                            # It is assumed bitmaps = checkpoints, and none is a empty list:
                            echo "$domain: Checkpoints and bitmaps lists on disk $image MATCH"
                        else

                            backup_check_failed="true"
                            echo "$domain: ${#checkpoint_list[@]} checkpoints found, and ${#bitmaps_list[@]} bitmaps found on disk $image (backup chain is broken)"

                            # Nothing else can be done
                            break
                        fi
                    done
                fi

                # When above check failed or something was wrong from the very beginning, cleanses disk images,
                # checkpoints metadata (if any), and archives or deletes the existing backup chain, according the case:
                #------------------------------------------------------------------------------
                if [[ $backup_check_failed == true \
                    || $recoverable_backup_chain == false \
                    || $backup_folder_integrity == false ]]; then

                    if [[ $RESTARTED_SERVER != true ]]; then

                        # Deletes checkpoints metadata if any detected:
                        echo "$domain: Pruning existing checkpoints in QEMU..."
                        domain_delete_checkpoint $domain --all --metadata
                    fi

                    for image in $(domain_img_paths_list $domain); do

                        # Then deletes all bitmaps, in all image disks:
                        echo "$domain: Deleting bitmaps on disk image $image..."

                        for bitmap in $(disk_image_bitmap_list $image); do

                            disk_image_delete_bitmap $image $bitmap
                        done
                    done

                # Mark the backup chain status as broken:
                broken_or_full_backup_chain[$i]=$domain

                # If backup check was successful:
                #------------------------------------------------------------------------------
                else

                    # If backup chain is recoverable, cleanses the VM with the failed checkpoint:
                    #------------------------------------------------------------------------------
                    if [[ $recoverable_backup_chain == true ]]; then

                        # Checks used RAM
                        local memlimit_active=""
                        if [[ ! -z $VM_RAM_LIMIT && $(domain_getmem $domain --max) -gt $VM_RAM_LIMIT ]]; then

                            local original_ram_size=$(domain_getmem $domain)

                            # Sets temporal limits of RAM before to perform the operation:
                            memlimit_active="yes"
                            domain_setmem "$domain" "$VM_RAM_LIMIT"

                            [[ $? -eq 0 ]] \
                                    && echo "$domain: RAM size temporarily throttled from ${original_ram_size// / \/ } to $VM_RAM_LIMIT KiB for this task" \
                                    || echo "WARNING: Failed to set $domain RAM size to user defined limit of $VM_RAM_LIMIT KiB"
                        fi

                        domain_start $domain --nowait

                        echo "$domain: Removing damaged checkpoint: ${checkpoint_list[-1]} ..."
                        domain_delete_checkpoint $domain ${checkpoint_list[-1]}

                        domain_shutdown $domain --nowait

                        if [[ ! -z $memlimit_active ]]; then

                            # Reverts RAM limits when these was previously changed:
                            domain_setmem "$domain" "$original_ram_size"

                            [[ $? -eq 0 ]] \
                                && echo "$domain: Reverted RAM size to its original setting of ${original_ram_size// / \/ } KiB" \
                                || echo "WARNING: Failed to revert $domain RAM size to its original setting!"
                        fi
                    fi

                    # Backup chain will be treated as preserved:
                    preserved_backup_chain+=($domain)
                fi

            # When VM is running, performs a simpler checkpoint check in case is worth to proceed.
            #------------------------------------------------------------------------------
            else

                if [[ $backup_folder_integrity == true || $recoverable_backup_chain == true ]]; then

                    echo "$domain: VM appears to be running, comparing QEMU and Backup's checkpoint lists..."

                    # Gets both qemu and backup checkpoint lists:
                    checkpoint_list=($(domain_checkpoint_list $domain))

                    local backup_chain_checkpoint_list=($(backup_checkpoint_list $LOCAL_BACKUP_PATH/$domain))

                    if [[ ${checkpoint_list[@]} == ${backup_chain_checkpoint_list[@]} ]]; then

                        echo "$domain: QEMU and Backup's checkpoint lists MATCH"

                        if [[ $recoverable_backup_chain == true ]]; then

                            echo "$domain: Removing damaged checkpoint: ${checkpoint_list[-1]} ..."
                            domain_delete_checkpoint $domain ${checkpoint_list[-1]}

                            echo "$domain: Power cycling VM to apply changes..."
                            domain_powercycle $domain $VM_WAIT_TIME
                        fi

                        # Backup chain is OK, mark as preserved:
                        preserved_backup_chain+=($domain)

                    else

                        echo "$domain: QEMU and Backup's checkpoint lists MISMATCH"

                        # Mark the backup chain status as broken:
                        broken_or_full_backup_chain[$i]=$domain

                        # Additionally, mark it as non recoverable (to be archived):
                        recoverable_backup_chain="false"

                    fi

                # Virtnbdbackup can take care of checkpoints/bitmaps in this scenario:
                #------------------------------------------------------------------------------
                else

                    # Mark the backup chain status as broken:
                    broken_or_full_backup_chain[$i]=$domain
                fi
            fi

            # Final step is to process backup chain files according the results:
            #------------------------------------------------------------------------------
            if [[ $recoverable_backup_chain == true ]]; then

                # Recoverable backup chain passed the test. Delete the demaged checkppoint and keep the backup chain:
                echo "$domain: Fixing backup chain data in $LOCAL_BACKUP_PATH/$domain ..."

                # Deletes any related file with the damaged checkpoint:
                find $LOCAL_BACKUP_PATH/$domain -name \*${checkpoint_list[-1]}* -type f -delete

                # Deletes the last checkpoint from the list:
                unset checkpoint_list[-1]

                # Create a stringified variable to export updated list
                local new_checkpoint_list="${checkpoint_list[@]}"

                # Rebuilds the cpt file with the parsed new list of checkpoints:
                echo "[\"${new_checkpoint_list// /\", \"}\"]" > $LOCAL_BACKUP_PATH/$domain/$domain.cpt

            elif [[ $recoverable_backup_chain == false || $backup_check_failed == true || $backup_chain_full == true ]]; then

                # Backup chain can't be used anymore, but it's total or partially recoverable.
                # Processes backup for being archived locally (and remotely, if set) applying 2nd part of retention policy:
                archive_backup $LOCAL_BACKUP_PATH/$domain $LOCAL_BACKUP_CHAINS_TO_KEEP
                [[ ! -z $RSYNC_BACKUP_PATH ]] && archive_remote_backup $RSYNC_BACKUP_PATH/$domain $RSYNC_BACKUP_CHAINS_TO_KEEP

            elif [[ $backup_folder_integrity == false ]]; then

                # Unrecoverable or unexistent backup chain folder. Delete it:
                rm -rf $LOCAL_BACKUP_PATH/$domain

                # But keep existing remote ones, if remote path is set, without apply retention policy:
                [[ ! -z $RSYNC_BACKUP_PATH ]] && archive_remote_backup $RSYNC_BACKUP_PATH/$domain
            fi

            # Exits the loop:
            break

        done

        # Increases the index to check the next VM:
        ((i++))
    done

    # Cleanse CHECK_BACKUPS_LIST, since all VMs were processed, and copied into correspondent lists:
    unset CHECK_BACKUPS_LIST

    # Writes updated SCHEDULED_BACKUPS_LIST value:
    # as a string, since sed can't expand arrays correctly:
    SCHEDULED_BACKUPS_LIST+=(${preserved_backup_chain[@]})
    SCHEDULED_BACKUPS_LIST="${SCHEDULED_BACKUPS_LIST[@]}"

    # And updates values externally:
    sed -i \
    -e "s/CHECK_BACKUPS_LIST=.*/CHECK_BACKUPS_LIST=()/" \
    -e "s/SCHEDULED_BACKUPS_LIST=.*/SCHEDULED_BACKUPS_LIST=($SCHEDULED_BACKUPS_LIST)/" \
    $external_vars

    # Turn again stringified variables back into lists:
    SCHEDULED_BACKUPS_LIST=($SCHEDULED_BACKUPS_LIST)

    # Appends sub-list to global list of VMs in need of a new backup chain:
    CREATE_BACKUP_CHAIN_LIST+=(${broken_or_full_backup_chain[@]})

    # Appends sub-list to the global list of powered OFF VMs:
    POWEREDOFF_VMS_LIST+=(${domain_shutdown_success[@]})

    # Appends sub-list of failed to shutdown VMs to global list of VMs with issues
    SHUTDOWN_REQUIRED_VMS_LIST+=(${domain_shutdown_failed[@]})

    echo ""
    echo "Backup Chain Integrity Summary:"
    echo ""
    echo "Added to Scheduled Backups:   ${preserved_backup_chain[@]:-"None"}"
    echo "In need of new backup chain:  ${broken_or_full_backup_chain[@]:-"None"}"
    [[ ! -z $VM_ALLOW_POWERCYCLE ]] && \
    echo "Into automatic power cycle:   ${domain_shutdown_success[@]:-"None"}" || \
    echo "Manual shut down is required: ${domain_shutdown_failed[@]:-"None"}"

    if [[ -z ${domain_shutdown_failed[@]} ]]; then

        echo ""
        echo "All Backup Chains Checked!"
    fi
}

#------------------------------------------------------------------------------
# Creates backup chains for VMs in CREATE_BACKUP_CHAIN_LIST, managing temporal RAM limits (when set) and powering on/off as necessary:
#------------------------------------------------------------------------------
create_backup_chain()
{
    # Local variables used for flow control:
    local original_ram_size
    local memlimit_active

    # Lists to add VMs (and summarize at the end):
    local backup_chain_failed
    local backup_chain_success
    local domain_poweron_failed
    local domain_poweron_success
    local remote_sync_failed
    local remote_sync_success
    local rsync_failed_status
    local virsh_failed_status
    local virtnbdbackup_failed_status

    echo ""
    echo "___________________________________________________________________________________________________"
    echo "Creating Backup chains for Virtual machines: ${CREATE_BACKUP_CHAIN_LIST[@]}"

    [[ $(os_is_unraid) == yes ]] && unraid_notify "normal" "VM-Babysitter" "Backup chain creation" "In progress for ${CREATE_BACKUP_CHAIN_LIST[@]}. Avoid to stop/restart this container until further notice"

    local i=0
    for domain in ${CREATE_BACKUP_CHAIN_LIST[@]}; do

        original_ram_size=""
        memlimit_active="no"

        echo ""

        while true; do

            if [[ $(domain_state $domain) == running ]]; then

                # Only when VM is running, attempts to create a new backup chain:
                do_backup_chain $domain "full" $LOCAL_BACKUP_PATH $VIRTNBDBACKUP_ARGS

                if [[ $? -eq 0 ]]; then

                    # Backup chain creation was successful!
                    backup_chain_success[$i]=$domain
                else

                    # Get last state for virtnbdbackup:
                    virtnbdbackup_failed_status=$?

                    # Failed to create a new backup chain:
                    backup_chain_failed[$i]=$domain

                    # Delete partial files (unusable garbage):
                    rm -rf $LOCAL_BACKUP_PATH/$domain
                fi

                if [[ ${domain_poweron_success[$i]} == $domain ]]; then

                    # VM was previously shut off, revert to its previous state:
                    domain_shutdown $domain --nowait

                    if [[ $memlimit_active == yes ]]; then

                        # RAM was previously throttled. Reverting to its original values:
                        domain_setmem "$domain" "$original_ram_size"

                        [[ $? -eq 0 ]] \
                            && echo "$domain: Reverted RAM size to its original setting of ${original_ram_size// / \/ } KiB" \
                            || echo "WARNING: Failed to revert $domain RAM size to its original setting!"
                    fi
                fi

                if [[ ${backup_chain_success[$i]} == $domain && ! -z $RSYNC_BACKUP_PATH ]]; then

                    # Backup chain creation was successful and remote endpoint is (correctly) set,
                    # attempts to transfer changes via rsync:

                    echo "$domain: Copying new backup chain to configured remote mirror..."

                    # Transfer backup using SSH_OPTIONS and RSYNC_ARGS:
                    rsync $RSYNC_ARGS -e "ssh $SSH_OPTIONS" $LOCAL_BACKUP_PATH/$domain/ $RSYNC_BACKUP_PATH/$domain/

                    # Depending on success with rsync, will add the VM to $remote_success or $remote_fail
                    if [[ $? -eq 0 ]]; then

                        # When rsync exited normally, adds the VM to $remote_sync_success:
                        remote_sync_success[$i]+=$domain
                        echo "$domain: New backup chain was copied successfuly to configured remote mirror"
                    else

                        # Get last state for virtnbdbackup:
                        rsync_failed_status=$?

                        # Adds the VM to $remote_sync_failed list:
                        remote_sync_failed[$i]+=$domain
                        echo "$domain: Failed to copy new backup chain to configured remote mirror with status $rsync_failed_status"
                    fi
                fi

                # Exits the loop:
                break

            else
                # VM is presumably shut off. Will attempts to start it:
                if [[ ! -z $VM_RAM_LIMIT ]]; then

                    # And needs to check how much memory uses by default, throttling it if limits are established:
                    if [[ $(domain_getmem $domain --max) -gt $VM_RAM_LIMIT ]]; then

                        # If max value is greater than the established limit, sets the VM RAM temporarily to such limit:
                        memlimit_active="yes"

                        # Saves apart original RAM sizes:
                        original_ram_size=$(domain_getmem $domain)

                        # Applies temporal values (according user input, but values are grabbed from virsh in KiB):
                        domain_setmem "$domain" "$VM_RAM_LIMIT"

                        [[ $? -eq 0 ]] \
                            && echo "$domain: RAM size temporarily throttled from ${original_ram_size// / \/ } to $VM_RAM_LIMIT KiB for this task" \
                            || echo "WARNING: Failed to set $domain RAM size to user defined limit of $VM_RAM_LIMIT KiB"
                    fi
                fi

                # Attempts to start the VM (awaits for VM's QEMU agent):
                domain_start $domain --wait $VM_WAIT_TIME
                if [[ $? -eq 0 ]]; then

                    domain_poweron_success[$i]=$domain

                    # Restarts the loop to chech VM under changed conditions:
                    continue
                else

                    # VM failed to power on. This is an abnormal situation:

                    # Get last state for virsh:
                    virsh_failed_status=$?

                    echo "$domain: Failed to start with virsh status: $virsh_failed_status (no backup chain could be created)"
                    domain_poweron_failed[$i]=$domain

                    # Breaks the loop:
                    break
                fi
            fi
        done

        # Increases the index to check the next VM:
        ((i++))
    done

    # Cleanse CREATE_BACKUP_CHAIN_LIST, since all VMs were processed, and copied into correspondent lists:
    unset CREATE_BACKUP_CHAIN_LIST

    # Appends updated values:
    SCHEDULED_BACKUPS_LIST+=(${backup_chain_success[@]})

    FAILED_VMS_LIST+=(${domain_poweron_failed[@]})
    FAILED_VMS_LIST+=(${backup_chain_failed[@]})

    # And updates them all at once:
    SCHEDULED_BACKUPS_LIST="${SCHEDULED_BACKUPS_LIST[@]}"
    FAILED_VMS_LIST="${FAILED_VMS_LIST[@]}"

    sed -i \
    -e "s/SCHEDULED_BACKUPS_LIST=.*/SCHEDULED_BACKUPS_LIST=($SCHEDULED_BACKUPS_LIST)/" \
    -e "s/FAILED_VMS_LIST=.*/FAILED_VMS_LIST=($FAILED_VMS_LIST)/" \
    $external_vars

    # Turn again stringified variables back into lists:
    SCHEDULED_BACKUPS_LIST=($SCHEDULED_BACKUPS_LIST)
    FAILED_VMS_LIST=($FAILED_VMS_LIST)

    # And shows the summary at the very end:

    echo ""
    echo "Backup Chain Creation Summary:"
    echo ""
    echo "Added to Scheduled Backups:        ${backup_chain_success[@]:-"None"}"
    echo "Could not create new backup chain: ${backup_chain_failed[@]:-"None"}"
    echo "Could not power on:                ${domain_poweron_failed[@]:-"None"}"

    if [[ ! -z $RSYNC_BACKUP_PATH ]]; then

        # Only show remote stats when remote endppoint is set:
        echo ""
        echo "Success copying to remote mirror: ${remote_sync_success[@]:-"None"}"
        echo "Could not copy to remote mirror:  ${remote_sync_failed[@]:-"None"}"
    fi

    if [[ -z ${backup_chain_failed[@]} && -z ${domain_poweron_failed[@]} && -z ${remote_sync_failed[@]} ]]; then

        echo ""
        echo "All Backup Chains Created!"

        [[ $(os_is_unraid) == yes ]] && unraid_notify "normal" "VM-Babysitter" "Backup chain creation" "Success"

    elif [[ $(os_is_unraid) == yes ]]; then

        [[ ! -z ${domain_poweron_failed[@]} ]] && unraid_notify "warning" "VM-Babysitter" "Virsh failed (last status: $virsh_failed_status)" "Could not power on: ${domain_poweron_failed[@]}"

        [[ ! -z ${backup_chain_failed[@]} ]] && unraid_notify "warning" "VM-Babysitter" "Virtnbdbackup failed (last status: $virtnbdbackup_failed_status)" "Could not create backup chain(s) for: ${backup_chain_failed[@]}"

        [[ ! -z ${remote_sync_failed[@]} ]] && unraid_notify "warning" "VM-Babysitter" "Rsync failed (last status: $rsync_failed_status)" "Could not sync backup chain(s) of: ${remote_sync_failed[@]} (Will be re-attempted on next schedule)"
    fi
}

###############################################################################

# User variables defaults (details on README.md):
#------------------------------------------------------------------------------

BACKUP_SCHEDULE=${BACKUP_SCHEDULE:-"@daily"}
LOCAL_BACKUP_CHAINS_TO_KEEP=${LOCAL_BACKUP_CHAINS_TO_KEEP:-""}
LOCAL_BACKUP_PATH=${LOCAL_BACKUP_PATH:-"/backups"}
LOGFILE_PATH=${LOGFILE_PATH:-"/logs/vm-babysitter.log"}
LOGROTATE_CONFIG_PATH=${LOGROTATE_CONFIG_PATH:-"/tmp/logrotate.d/vm-babysitter"}
LOGROTATE_SCHEDULE=${LOGROTATE_SCHEDULE:-"@daily"}
LOGROTATE_SETTINGS=${LOGROTATE_SETTINGS:-"compress\ncopytruncate\ndateext\ndateformat -%Y%m%d-%s\nmissingok\nrotate 30"}
MAX_BACKUPS_PER_CHAIN=${MAX_BACKUPS_PER_CHAIN:-"30"}
RSYNC_ARGS=${RSYNC_ARGS:-"-a"}
RSYNC_BACKUP_CHAINS_TO_KEEP=${RSYNC_BACKUP_CHAINS_TO_KEEP:-""}
RSYNC_BACKUP_PATH=${RSYNC_BACKUP_PATH:-""}
SSH_OPTIONS=${SSH_OPTIONS:-"-q -o IdentityFile=/private/hostname.key -o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"}
[[ -f /usr/share/zoneinfo/$TZ ]] && local_timezone_file="/usr/share/zoneinfo/$TZ"
UNRAID_NOTIFY_HOST=${UNRAID_NOTIFY_HOST:-"localhost"}
VIRTNBDBACKUP_ARGS=${VIRTNBDBACKUP_ARGS:-""}
VM_ALLOW_POWERCYCLE=${VM_ALLOW_POWERCYCLE:-""}
VM_AUTOSTART_LIST=${VM_AUTOSTART_LIST:-""}
VM_IGNORED_LIST=${VM_IGNORED_LIST:-""}
[[ ! -z $VM_RAM_LIMIT ]] && VM_RAM_LIMIT=$(numfmt --from=iec --to-unit=1Ki ${VM_RAM_LIMIT^^})
VM_WAIT_TIME=${VM_WAIT_TIME:-"60"}

# Internal Variables:
#------------------------------------------------------------------------------

# Temporal crontab file (to be loaded for cron)
crontab_file="/tmp/crontab"

# Storing file for bash like lists shared between this script and the scheduler:
external_vars="/tmp/vm-babysit-vars"

# Main library where common functions and some variables are loaded:
functions_path="/usr/local/bin/vm-functions"

# Path of the scheduler script (run by cron):
scheduled_backup_script="/usr/local/bin/update_backup_chain"

# Main execution:
###############################################################################

# Redirect system stdout and stderr to $LOGFILE_PATH:
exec > >(tee -a $LOGFILE_PATH) 2> >(tee -a $LOGFILE_PATH >&2)

# Load functions:
source $functions_path

# Create internal folders in case don't exist:
[[ ! -d $( dirname $LOGFILE_PATH) ]] && mkdir -p $(dirname $LOGFILE_PATH)

# Sets the local timezone (if ENV TZ was set):
if [[ ! -z $local_timezone_file ]]; then

    ln -fs $local_timezone_file /etc/localtime
    &> /dev/null dpkg-reconfigure -f noninteractive tzdata
fi

# Catches the signal sent from docker to stop execution:
# The most gracefully way to stop this container is with:
# 'docker kill --signal=SIGTERM <docker-name-or-id>'
trap 'stop_container' SIGTERM

#------------------------------------------------------------------------------
# 1. Check input parameters (exits on error)
#------------------------------------------------------------------------------

echo "############################################################################################################"
echo "Container started at: $(date "+%Y-%m-%d %H:%M:%S") ($(cat /etc/timezone))"
echo "############################################################################################################"

# 1.1 Check DOMAINS_LIST:
#------------------------------------------------------------------------------
echo ""
echo "Querying for persistent Virtual machines from libvirt..."

# The initial list of VMs to work:
DOMAINS_LIST=($(domains_list))

if [[ ! -z ${DOMAINS_LIST[@]} ]]; then

    # 1.1.1 Check VM_IGNORED_LIST:
    #------------------------------------------------------------------------------
    if [[ ! -z $VM_IGNORED_LIST ]]; then

    echo ""

        for domain in $VM_IGNORED_LIST; do

            if [[ $(domain_exists $domain) == yes ]]; then

                # Remove the VM from DOMAINS_LIST
                unset DOMAINS_LIST[$(item_position $domain "DOMAINS_LIST")]

                # Rebuild indexes into the array:
                DOMAINS_LIST=(${DOMAINS_LIST[@]})

                echo "$domain: Into VM_IGNORED_LIST, therefore ignored"
            else
                echo "WARNING: VM '$domain' in VM_IGNORED_LIST not found!"
            fi
        done
    fi

    # 1.1.2 Check VM_AUTOSTART_LIST:
    #------------------------------------------------------------------------------
    if [[ ! -z $VM_AUTOSTART_LIST ]]; then

    echo ""

    i=0
        for domain in $VM_AUTOSTART_LIST; do

            if [[ $(domain_exists $domain) == yes ]]; then

                # Add VM to the list of VMs to be powered on when monitor starts:
                POWEREDOFF_VMS_LIST+=($domain)
                echo "$domain: Into VM_AUTOSTART_LIST, therefore will be started (after initial check)"
            else

                echo "WARNING: VM $domain in VM_AUTOSTART_LIST not found!"
            fi
            ((i++))
        done
    fi

    # 1.1.3 Check DOMAINS_LIST VM's disk images:
    #------------------------------------------------------------------------------

    echo ""

    i=0
    for domain in ${DOMAINS_LIST[@]}; do

        drives_list=($(domain_drives_list $domain))
        if [[ ! -z ${drives_list[@]} ]]; then

            # Does have drives able to be backed up. Checks if such disk images are reachable inside the container:
            images_list=($(domain_img_paths_list $domain))
            for image in ${images_list[@]}; do

                if [[ ! -f $image ]]; then

                    FAILED_VMS_LIST+=($domain)

                    echo "ERROR: $domain's disk image: $image not found. Ensure you mount -and mirror- this correctly inside the container (e.g. '-v /common/path/to/vms/disks:/common/path/to/vms/disks')"

                elif [[ ! -r $image && ! -w $image ]]; then

                    FAILED_VMS_LIST+=($domain)

                    echo "ERROR: $domain's disk image: $image has permission issues (cannot be read or written)"
                fi
            done
        else

            # Exclude VMs without disks images that can be backed up:
            unset DOMAINS_LIST[$i]

            # Rebuild indexes into the array:
            DOMAINS_LIST=(${DOMAINS_LIST[@]})

            echo "WARNING: VM $domain has no drives that can be backed up, therefore will be ignored"
        fi
        ((i++))
    done

    # Re-check DOMAINS_LIST after the above procedure (ignored and left aside by other issues):
    if [[ ! -z ${DOMAINS_LIST[@]} ]]; then

        # VMs are left after initial checks, then domain_list_status is correct:
        domains_list_status="OK"

        echo "Persistent Virtual machine(s) able to be backed up: ${DOMAINS_LIST[@]}"

    elif [[ ! -z ${FAILED_VMS_LIST[@]} ]]; then

        # No VMs are left, but one or more failed the initial checks:
        echo "ERROR: Issues detected with '${FAILED_VMS_LIST[@]}' that need to be solved before to run this container again"

    else
        echo "WARNING: After initial check, no persistent Virtual machines are left available for backup"
    fi
else
    # No VMs were found from the beginning:
    echo "ERROR: No persistent Virtual machines were found!"
fi

# 1.2 Check MAX_BACKUPS_PER_CHAIN
#------------------------------------------------------------------------------
# Check for LOCAL_BACKUP_CHAINS_TO_KEEP:
if [[ $MAX_BACKUPS_PER_CHAIN =~ [0-9] ]]; then

    # Is an integer number:
    max_backups_per_chain_status="OK"
    echo "Max backups to save per chain: $MAX_BACKUPS_PER_CHAIN"

elif [[ -z $MAX_BACKUPS_PER_CHAIN ]]; then

    # Was not set, warn the user about the potential issue:
    max_backups_per_chain_status="UNUSED"
    echo "WARNING: Environment variable MAX_BACKUPS_PER_CHAIN is not set. You should set a reasonable limit for the number of backups, or use the default value. Otherwise the backup chain will grow without any control, filling up your storage!"

else
    # Invalid value:
    max_backups_per_chain_status="FAILED"
    echo "ERROR: Incorrect value for environment variable MAX_BACKUPS_PER_CHAIN: '$MAX_BACKUPS_PER_CHAIN' <- It must be a natural integer"
fi

# 1.3 Check LOCAL_BACKUP_PATH
#------------------------------------------------------------------------------

echo ""

if  [[ -d $LOCAL_BACKUP_PATH ]]; then

    # $LOCAL_BACKUP_PATH found
    if  [[ -r $LOCAL_BACKUP_PATH && -w $LOCAL_BACKUP_PATH ]]; then

        # $LOCAL_BACKUP_PATH has read/write permissions.
        local_backup_path_status="OK"
        echo "Backups main path internally set to: $LOCAL_BACKUP_PATH"

        # Check for LOCAL_BACKUP_CHAINS_TO_KEEP:
        if [[ $LOCAL_BACKUP_CHAINS_TO_KEEP =~ [0-9] ]]; then

            # Is an integer number:
            echo "Max backup chains per VM to keep locally: $LOCAL_BACKUP_CHAINS_TO_KEEP"

        elif [[ -z $LOCAL_BACKUP_CHAINS_TO_KEEP ]]; then

            # Was not set:
            echo "Environment variable LOCAL_BACKUP_CHAINS_TO_KEEP not set. ALL recoverable backup chains will be archived locally"

        else
            # Invalid value (unsets the 'OK' status):
            unset local_backup_path_status
            echo "ERROR: Incorrect value for environment variable LOCAL_BACKUP_CHAINS_TO_KEEP: '$LOCAL_BACKUP_CHAINS_TO_KEEP' <- It must be a natural integer"
        fi
    else

        echo "ERROR: Backups main path: $LOCAL_BACKUP_PATH <- Permission issues (cannot be read or written)"
    fi
else

    echo "ERROR: Backups main path: $LOCAL_BACKUP_PATH  <- Not found inside the container. Ensure you mount this correctly (e.g. '-v /path/to/backups-main-path:/$LOCAL_BACKUP_PATH')"
fi

# 1.4 Check RSYNC_BACKUP_PATH
#------------------------------------------------------------------------------

if [[ -z $RSYNC_BACKUP_PATH ]]; then

    rsync_backup_path_status="UNUSED"
    echo ""
    echo "Environment variable RSYNC_BACKUP_PATH not set. No remote backup endpoint will be used"

elif [[ $RSYNC_BACKUP_PATH == *@*:/* ]]; then

    echo ""

    # Apparently includes correct remote login and path. Separates ssh login from remote path:
    rsync_server=$(echo $RSYNC_BACKUP_PATH | cut -d':' -f1)
    rsync_path=$(echo $RSYNC_BACKUP_PATH | cut -d':' -f2)

    # Attempts to comunicate with the remote host:
    ssh $SSH_OPTIONS $rsync_server "exit 0"
    rsync_server_status=$?

    if [[ $rsync_server_status == 0 ]]; then

        # Attempts to perform similar checks as with $LOCAL_BACKUP_PATH:
        rsync_backup_path_status=$(ssh $SSH_OPTIONS $rsync_server "[[ -d $rsync_path && -r $rsync_path && -w $rsync_path ]] && echo 'OK' || { mkdir -p $rsync_path; [[ -d $rsync_path ]] && echo 'CREATED' || echo 'FAILED'; }")


        if [[ $rsync_backup_path_status != FAILED ]]; then

            # Notifiy about good status of $rsync_path
            echo "$rsync_server: $rsync_path exists and status is '$rsync_backup_path_status'"

            # Verify # of backup chains to keep:
            if [[ $RSYNC_BACKUP_CHAINS_TO_KEEP =~ [0-9] ]]; then

                # Is an integer number:
                echo "Max backup chains per VM to keep remotely: $RSYNC_BACKUP_CHAINS_TO_KEEP"

            elif [[ -z $RSYNC_BACKUP_CHAINS_TO_KEEP ]]; then

                # Was not set:
                echo "All recoverable backup chains will be archived remotely"
            else

                echo "ERROR: Incorrect value for environment variable RSYNC_BACKUP_CHAINS_TO_KEEP: '$RSYNC_BACKUP_CHAINS_TO_KEEP' it must be a positive integer"
                rsync_backup_path_status="FAILED"
            fi

        else
            echo "ERROR: remote mirror $rsync_path cannot be read and/or written (or is not a directory)"
        fi

    else
        echo "ERROR: Connection with $rsync_server failed with status $rsync_server_status"
        rsync_backup_path_status="FAILED"
    fi
else
    echo "ERROR: Incorrect syntax for RSYNC_BACKUP_PATH: '$RSYNC_BACKUP_PATH' it must be SSH-like absolute path (e.g. user@host:/path-to-mirror)"
    rsync_backup_path_status="FAILED"
fi


# 1.5 TO DO: Check other ENV variables, and SSH key:
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# 2. Only when input parameters doesn't require to restart the container, it continues the rest of the checks:
#------------------------------------------------------------------------------

if [[ $domains_list_status == OK && $max_backups_per_chain_status != FAILED && $local_backup_path_status == OK && $rsync_backup_path_status != FAILED ]]; then

    # 2.0 Create logrotate config:
    #------------------------------------------------------------------------------

    if [[ -z $DISABLE_LOGROTATE ]]; then

        echo "Configuring logrotate..."

        # Create directory if doesn't exist:
        mkdir -p $(dirname $LOGROTATE_CONFIG_PATH)

        # Parse logrotate configuration (overwriting, if any previous):
        echo -e "$LOGFILE_PATH {\n$LOGROTATE_SETTINGS\n}" > $LOGROTATE_CONFIG_PATH
    else
        echo "Logrotate disabled by user"
        # Convert variable into a comment, to be added to crontab
        DISABLE_LOGROTATE="# "
    fi

    # 2.1 Create/update Cron task for VMs to be (progressively) included in $scheduled_backups_list:
    #------------------------------------------------------------------------------

    echo "Configuring $(basename $scheduled_backup_script)..."

    # Silently deletes any previous cron task:
    &> /dev/null crontab -r

    # Parses the actual cron task needed to run to $crontab_file
    # (Including ENV vars not being read from cron's environment):
    cat << end_of_crontab > $crontab_file
# Values below are refreshed upon container (re)start:

# Main environment is bash:
SHELL=/bin/bash

# Search paths for binaries and scripts:
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

# Environment variables passed through Docker:
LOCAL_BACKUP_PATH="$LOCAL_BACKUP_PATH"
MAX_BACKUPS_PER_CHAIN="$MAX_BACKUPS_PER_CHAIN"
RSYNC_BACKUP_PATH="$RSYNC_BACKUP_PATH"
RSYNC_ARGS="$RSYNC_ARGS"
SSH_OPTIONS="$SSH_OPTIONS"
VIRTNBDBACKUP_ARGS="$VIRTNBDBACKUP_ARGS"
UNRAID_NOTIFY_HOST="$UNRAID_NOTIFY_HOST"

# Paths for functions and (shared) dynamic variables:
functions_path="$functions_path"
external_vars="$external_vars"

# Schedule for $(basename $scheduled_backup_script):
$BACKUP_SCHEDULE $scheduled_backup_script > /proc/1/fd/1 2>&1

# Schedule for logrotate:
$DISABLE_LOGROTATE$LOGROTATE_SCHEDULE /usr/sbin/logrotate $LOGROTATE_CONFIG_PATH > /proc/1/fd/1 2>&1
end_of_crontab

    # Sets the cron task:
    crontab $crontab_file

    # Finally, runs cron and sends to background:
    echo "Starting Cron..."
    cron -f -l -L2 &

    # 2.2 Check if OS is Unraid and it has just been restarted (checking backups under this scenario assumes missing checkpoints / broken backup chains:
    #------------------------------------------------------------------------------

    echo ""

    if [[ $(os_is_unraid) == yes ]]; then

        echo "OS Unraid detected"

        for domain in $(domains_list); do

            # Looks for checkpoints in all VMs, only stopping if it finds something
            # (does not rely on expose checkpoints dir inside the container):
            [[ ! -z $(domain_checkpoint_list $domain) ]] && { checkpoints_found="yes"; break; }

        done

        if [[ -z $checkpoints_found ]]; then

            # RESTARTED_SERVER mode detected:
            RESTARTED_SERVER="true"
            echo "____________________________________________________________________________________________________________"
            echo "WARNING: None of the persistent VM has previous checkpoints! This server might have been restarted recently, so a more comprehensive check is required"
            echo "Virtual machine(s) set for backup are in need to be Shut Down in order to check its backup chain integrity, rebuilding/fixing as needed"
            echo ""

            for domain in ${DOMAINS_LIST[@]}; do

                if [[ $(domain_state $domain) != "shut off" ]]; then

                    if [[ ! -z $VM_ALLOW_POWERCYCLE ]]; then

                        domain_shutdown $domain --wait $VM_WAIT_TIME
                        if [[ $? -eq 0 ]]; then

                            # And into this list to be started as checks has been completed:
                            POWEREDOFF_VMS_LIST+=($domain)

                            # Adds successfully shut off VMs to the initial queue:
                            CHECK_PATCH_LIST+=($domain)

                        else

                            # VM Delayed too much without being shutdown. Added to this queue to be checked up periodically:
                            SHUTDOWN_REQUIRED_VMS_LIST+=($domain)
                        fi
                    else

                        # User needs to shutdown this VM before to perform any further checks:
                        SHUTDOWN_REQUIRED_VMS_LIST+=($domain)
                    fi
                else

                    # Adds already shut down VMs to the initial queue:
                    CHECK_PATCH_LIST+=($domain)
                fi
            done

            echo "RESTARTED_SERVER mode Summary:"
            echo "Ready for further checks:     ${CHECK_PATCH_LIST[@]:-"None"}"
            [[ ! -z $VM_ALLOW_POWERCYCLE ]] && \
            echo "Into automatic power cycle:   ${POWEREDOFF_VMS_LIST[@]:-"None"}" || \
            echo "Manual shut down is required: ${SHUTDOWN_REQUIRED_VMS_LIST[@]:-"None"}"
        else

            # Fortunately there's not a 'RESTARTED_SERVER' scenario.
            # Add all remaining VMs in DOMAINS_LIST to the first queue:
            CHECK_PATCH_LIST=(${DOMAINS_LIST[@]})

            # Exports the variable, since it's modified by the scheduled script:
            RESTARTED_SERVER="false"
        fi
    else

        # OS is not Unraid.
        # Add all remaining VMs in DOMAINS_LIST to this queue:
        CHECK_PATCH_LIST=(${DOMAINS_LIST[@]})
    fi

    # 2.3 Initializes a file with variables externally stored, to be shared with the scheduler:
    #------------------------------------------------------------------------------
    cat << end_of_external_variables > $external_vars
# Shared values between $(basename %0) and $scheduled_backup_script. DO NOT EDIT!:

# Dynamic arrays:
CHECK_BACKUPS_LIST=()
FAILED_VMS_LIST=()
SCHEDULED_BACKUPS_LIST=()

# Dynamic strings:
ONGOING_BACKUP="false"
ONGOING_CHECK="false"
RESTARTED_SERVER=$RESTARTED_SERVER
end_of_external_variables

    # 3. Begin monitorization for VMs in lists, performing operations as required:
    #------------------------------------------------------------------------------

    echo ""
    echo "############################################################################################################"
    echo "Monitoring mode started"

    while true; do

        # Maximum standby period for monitoring should not exceed 10 seconds in any case,
        # because it could ignore SIGTERM from Docker, thus being killed with SIGKILL:
        sleep 1

        # 3.1 (Re)reads all external variables (presumably modified by $scheduled_backup_script):
        #------------------------------------------------------------------------------
        source $external_vars

        if [[ $ONGOING_BACKUP == false ]]; then

            if [[ ! -z ${SHUTDOWN_REQUIRED_VMS_LIST[@]} ]]; then

                # 3.2 Check first for VMs which are in need of shutdown.
                # (This normally happens when the user took the action, or when a VM took long time to shutdown):
                #------------------------------------------------------------------------------
                i=0
                for domain in ${SHUTDOWN_REQUIRED_VMS_LIST[@]}; do

                    if [[ $(domain_state $domain) == "shut off" ]]; then

                        # Move to main queue for check:
                        CHECK_PATCH_LIST+=($domain)
                        unset SHUTDOWN_REQUIRED_VMS_LIST[$i]

                        # Rebuild indexes into the array:
                        SHUTDOWN_REQUIRED_VMS_LIST=(${SHUTDOWN_REQUIRED_VMS_LIST[@]})

                        [[ $(os_is_unraid) == yes ]] && unraid_notify "normal" "VM-Babysitter" "Required shut down detected" "Resuming check/backup for $domain"
                    fi
                done
            fi

            if [[ ! -z ${CHECK_PATCH_LIST[@]} || ! -z ${CHECK_BACKUPS_LIST[@]} || ! -z ${CREATE_BACKUP_CHAIN_LIST[@]} ]]; then

                # 3.3 Fresh start, or status of at least on VM has changed, and sent to one of the queues. Marks an ongoing check starting:
                #------------------------------------------------------------------------------
                ONGOING_CHECK="true"
                sed -i \
                -e "s/ONGOING_CHECK=.*/ONGOING_CHECK=\"$ONGOING_CHECK\"/" $external_vars

                echo ""
                echo "____________________________________________________________________________________________________________"
                echo "Automatic check for VM(s) ${CHECK_PATCH_LIST[@]} ${CHECK_BACKUPS_LIST[@]} ${CREATE_BACKUP_CHAIN_LIST[@]} in progress..."

                # 3.3.1 Check for incremental backups patch on all VMs:
                #------------------------------------------------------------------------------
                [[ ! -z ${CHECK_PATCH_LIST[@]} ]] && check_patch

                # 3.3.2 Check for backup state (and apply retention policy) on all VMs:
                #------------------------------------------------------------------------------
                [[ ! -z ${CHECK_BACKUPS_LIST[@]} ]] && check_backups

                # Both sub-routines invoked above require to shut down VMs in order to proceed
                # They do this automatically if env variable VM_ALLOW_POWERCYCLE is set.
                # After they finish, VMs are started if in the global list below:
                if [[ ! -z ${POWEREDOFF_VMS_LIST[@]} ]]; then

                    # 3.3.3 Turns on all VMs that was previously shutdown for checks:
                    #------------------------------------------------------------------------------
                    echo ""
                    i=0
                    for domain in ${POWEREDOFF_VMS_LIST[@]}; do

                        if [[ $(domain_state $domain) != running ]]; then

                            # Turn on the VM. Do not wait for Guest's QEMU agent:
                            domain_start $domain --nowait
                        fi

                        # Remove the VM from the list is being read:
                        unset POWEREDOFF_VMS_LIST[$i]

                        # Rebuild indexes into the array:
                        POWEREDOFF_VMS_LIST=(${POWEREDOFF_VMS_LIST[@]})

                        # Increases the counter:
                        ((i++))
                    done
                fi

               # 3.3.4 Create new backup chains for VMs that require it:
               #------------------------------------------------------------------------------
               [[ ! -z ${CREATE_BACKUP_CHAIN_LIST[@]} ]] && create_backup_chain

                # 3.4 Show status report and notify about user actions, if required:
                #------------------------------------------------------------------------------
                echo ""
                echo "############################################################################################################"
                echo "All VMs with status changed finished to be processed at $(date "+%Y-%m-%d %H:%M:%S")"
                echo ""
                echo "VM-Babysitter Global Summary:"
                echo ""
                echo "Current Scheduled Backups:    ${SCHEDULED_BACKUPS_LIST[@]:-"None"}"
                echo "Manual Shut Down Required:    ${SHUTDOWN_REQUIRED_VMS_LIST[@]:-"None"}"
                echo "Misbehaving Virtual Machines: ${FAILED_VMS_LIST[@]:-"None"}"

                if [[ ! -z ${SCHEDULED_BACKUPS_LIST[@]} ]] && \
                [[ -z ${SHUTDOWN_REQUIRED_VMS_LIST[@]} ]] && \
                [[ -z ${FAILED_VMS_LIST[@]} ]]; then

                    echo ""
                    echo "All Virtual Machines Running Under Incremental Backups!"

                elif [[ ! -z ${SHUTDOWN_REQUIRED_VMS_LIST[@]} || ! -z ${FAILED_VMS_LIST[@]} ]]; then

                    user_action_message="USER ACTION IS REQUIRED!"

                    echo ""
                    echo $user_action_message

                    if [[ ! -z ${SHUTDOWN_REQUIRED_VMS_LIST[@]} ]]; then

                        shutdown_required_message="Perform a manual SHUT DOWN of: ${SHUTDOWN_REQUIRED_VMS_LIST[@]} as SOON as POSSIBLE! This is needed to allow being checked automatically (can't perform checks/backups until action has been taken)"

                        echo "WARNING: $shutdown_required_message"
                        [[ $(os_is_unraid) == yes ]] && unraid_notify "warning" "VM-Babysitter" "$user_action_message" "$shutdown_required_message"
                    fi

                    if [[ ! -z ${FAILED_VMS_LIST[@]} ]]; then

                        failed_vms_message="Perform a FULL MANUAL CHECK of: ${FAILED_VMS_LIST[@]} as SOON as POSSIBLE! Some check, backup or another operation failed unexpectedly. Check $(basename $LOGFILE_PATH) for detailed info"

                        echo  "ERROR: $failed_vms_message"
                        [[ $(os_is_unraid) == yes ]] && unraid_notify "alert" "VM-Babysitter" "$user_action_message" "$failed_vms_message"
                    fi
                fi

                # 3.5 Marks ongoing check as finished (entering in 'silent' mode):
                #------------------------------------------------------------------------------
                ONGOING_CHECK="false"
                sed -i \
                -e "s/ONGOING_CHECK=.*/ONGOING_CHECK=\"$ONGOING_CHECK\"/" $external_vars
            fi

        fi

        # 3.7 Restarts the loop from 3.1, until receives SIGTERM or SIGKILL from Docker
        #------------------------------------------------------------------------------
    done

else

    # Initial checks have proven non-recoverable errors:
    failed_initialize_message="Could not initialize due to errors! Check $(basename $LOGFILE_PATH) for detailed info"

    echo "ERROR: $failed_initialize_message"
    [[ $(os_is_unraid) == yes ]] && unraid_notify "alert" "VM-Babysitter" "Failed to start container" "$failed_initialize_message"

    stop_container
fi
